# 운영 서버 아키텍쳐의 이해

## 단일 서버

가장 기본적인 구성이다. 요청을 보내는 클라이언트와 요청을 처리하는 서버가 한 대 있다.  
서버 내에는 애플리케이션 코드와 데이터베이스가 실행된다.  
매우 단순한 구성인 만큼 환경을 구축하기 쉽기 때문에 테스트 서버나 간단한 애플리케이션을 서비스 할 때 많이 사용된다.  
데이터베이스와 애플리케이션이 같은 서버에서 실행되고 있기 때문에 별도의 네트워크 설정을 할 필요 없이 로컬 호스트를 대상으로 하면 된다.

하지만 다음과 같은 단점이 있다.

- 전체 서비스에 장애가 생길 확률이 높다.  
  애플리케이션과 데이터베이스가 같은 자원을 공유하기 때문에 둘 중 하나라도 자원을 모두 사용해버리거나 서버 하드웨어에 장애가 발생하면 해당 부분만 장애가 생기는 것이 아니라 전체 서비스가 완전히 죽어버린다.
- 서버 자원을 효율적으로 사용하기 어렵다.  
  애플리케이션과 데이터베이스는 각 속성에 따라 더 중요한 자원의 종류(CPU, 메모리, 디스크)나 최적화를 위해 필요한 OS 설정(I/O 컨드롤러, 디스크 설정)이 다를 수 있다.  
  둘 다 만족시키기 위해서는 필요 이상으로 고사양 서버르르 사용해야 할 수도 있다.
- 보안성이 떨어진다.  
  데이터베이스는 보안상 포트나 IP 등 접속 지점을 최소한으로 하는 것이 좋다.  
  하지만 웹 애플리케이션 특성상 다양한 IP 주소와 포트 번호에 대해 요청을 받을 수 있어야 하고 서버 내 여러 파일들도 업로드 될 수 있으므로 데이터베이스가 공격당할 가능성이 높아진다.
- 서버의 수를 여러 대로 늘려서 자원을 확장하는 스케일 아웃(scale out)이 힘들다.  
  서버 자원의 확장을 위해 서버를 여러 대로 늘려야 하는 경우 클라이언트에서는 추가된 서버들의 주소를 제대로 알아야 하며 데이터도 똑같은 복제본이 여러 개 생기므로 관리하기가 매우 힘들어진다.

## 애플리케이션/데이터베이스 서버 분리

단일 서버 구성에서 데이터베이스를 별도의 서버로 분리한 구성이다.  
애플리케이션과 데이터베이스가 다른 자원을 사용하기 때문에 단일 서버에서 나온 전체 서비스 장애 확률, 효율적인 자원 사용, 떨어지는 보안성과 같은 단점들이 해결된다.  
다만 두 대의 서버를 관리하기 때문에 구성이 조금 더 복잡해지고 서버 사이의 지연 시간과 네트워크 보안을 고려하기 시작해야 한다.  
그리고 클라이언트에서는 하나의 서버를 바라보고 있기 때문에 스케일 아웃은 여전히 힘들다.

## 서버 단위의 로드 밸런서

클라이언트가 애플리케이션을 실행하는 서버와 직접 통신하는 대신 로드 밸런서라는 서버와 통신하고 그 뒤에 여러 대의 애플리케이션 서버를 두는 방식이다.  
클라이언트는 로드 밸런서하고만 통신하고 로드 밸런서가 클라이언트에게서 받은 요청을 뒤에 있는 서버들에게 나눠준다.  
뒤에 있는 서버들이 요청을 처리하면 응답은 로드 밸런서를 통해 클라이언트에게 전달된다.

이 구성의 가장 큰 장점은 스케일 아웃이 가능해진다는 것이다.  
그리고 애플리케이션 서버 중 일부 서버에 장애가 발생해도 로드 밸런서에서 정상 서버에만 요청을 주면 되기 때문에 서비스 장애를 최소화할 수 있다.  
다만 모든 요청이 로드 밸런서를 통해 지나가기 때문에 로드 밸런서에 장애가 생기면 나머지 서버들이 정상이어도 전체 서비스 장애로 이어지기 때문에 주의해야 한다.  
또한 구성이 매우 복잡해진다는 단점이 있다.  
흔히 OSI 7 레이어의 L4 스위치라고 얘기하는 것이 이 로드 밸런서의 역할을 하는 장비다.
